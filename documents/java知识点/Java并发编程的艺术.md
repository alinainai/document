### 1.并发编程的挑战
并发目的: 让程序运行的更快。
挑战: 上线切换、死锁、受限于软硬件资源

#### 1.1 上下文切换
单核CPU也可以通过时间片实现多线程执行代码。时间片执行完后会切换任务，但是会保留上一个任务的状态，以便切回这个任务时加载这个任务的状态。
任务从保存到再加载的过程就是一次上下文切换。

多线程一定快吗？不一定，因为线程有创建和上下文切换的开销。

如何减少上下文切换

1. 无锁并发编程。如将数据ID按照Hash算法取模分段，不同的线程处理不同段的数据。
2. CAS算法。如 使用 Atomic 包
3. 使用最少线程。减少不必要的线程创建，避免任务少线程多，造成大量线程处于等待。
4. 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。

#### 1.2 死锁
死锁：
```kotlin
thread_a.start{
    synchronized(A){
        synchronized(B){}
    }
}
thread_b.start{
    synchronized(B){
        synchronized(A){}
    }
}
```
防止死锁

1. 避免一个线程同时获取多个锁。
2. 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
3. 尝试使用定时锁，使用 lock.tryLock(timeout) 来代替使用内部锁机制。
4. 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。

#### 1.3 资源限制的挑战

并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。
如：服务器带宽 2Mb/s，某个资源下载速度 1Mb/s，开10个线程去下载。
带来的问题：串行的代码采用并发执行，但是由于资源限制，仍在串行执行，还增加了上线文切换和资源调度的时间。

解决
- 解决硬件资源限制: 使用集群并发执行程序。
- 解决软件资源限制: 可以考虑使用资源池将资源复用。如：使用连接池将数据库和Socket连接复用

### 2. Java 并发机制的底层实现原理

.java -> .class -> jvm 执行 -> 汇编

#### 2.1 volatile 的应用

volatile: 轻量级的 synchronize，保证共享变量的可见性。不会引起线程上下文的切换和调度。
如果一个字段被声明成 volatile，Java 内存模型确保所有线程看到这个变量的值是一致的。
**有 volatile 修饰的变量进行写操作时会多出一个lock汇编代码。**

lock的作用：
1. 将当前处理器缓存行的数据写回到系统内存。
2. 这个写回内存的操作会使在其他CPU缓存了该内存地址的数据无效

通过总线嗅探机制实现缓存一致性。`锁总线` 优化为 `锁缓存`

追加字节优化性能，让数据填满 64 位的缓冲行。

#### 2.2 synchronized 的实现原理与应用

Java 中的每个对象都可以作为锁

1. 对于普通同步方法，锁是当前实例对象。
2. 对于静态同步方法，锁是当前类的Class对象。
3. 对于同步方法块，锁是 Synchronized 括号里配置的对象。

Jvm 基于进入和退出 Monitor 对象来实现方法同步和代码块同步。

使用 monitorenter(同步代码开始位置) 和 monitorexit(异常和结束位置) 指令实现。

对象头的 Mark Word











